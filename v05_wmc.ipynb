{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T14:09:42.305330Z",
     "start_time": "2019-03-01T14:09:42.232857Z"
    }
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import fastText\n",
    "import html\n",
    "import string\n",
    "import nltk\n",
    "from multiprocessing import Process\n",
    "import multiprocessing\n",
    "import time\n",
    "import sys\n",
    "from importlib import reload\n",
    "import redis\n",
    "# from urllib import request\n",
    "from urllib.parse import urlparse\n",
    "import requests as req\n",
    "# from lxml import html\n",
    "import logging\n",
    "# from scrapy.http import Request\n",
    "import requests\n",
    "import json\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from tabulate import tabulate\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "import mpld3\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "mpld3.enable_notebook()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:03:40.312298Z",
     "start_time": "2019-03-01T16:03:39.963969Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comparisons = pd.read_csv('df_comparisons_unsup_lemma.csv', index_col=0)\n",
    "df_news = pd.read_csv('df_news_unsup_lemma.csv',  parse_dates=['Datetime', 'Date'], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:46:43.946885Z",
     "start_time": "2019-03-01T16:46:43.936152Z"
    }
   },
   "outputs": [],
   "source": [
    "df_news.spot_pp_str.fillna('', inplace = True)\n",
    "df_news.text_pp_str.fillna('', inplace = True)\n",
    "df_news.title_pp_str.fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:03:46.748245Z",
     "start_time": "2019-03-01T16:03:46.741873Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_freq_unique(textnow):\n",
    "    \n",
    "    counts = Counter(textnow.split())\n",
    "\n",
    "    wordlist = []\n",
    "    countlist = []\n",
    "    for word, count in counts.items():\n",
    "        wordlist.append(word)\n",
    "        countlist.append(count)\n",
    "    countlist = np.array(countlist)\n",
    "#     countlist = countlist / countlist.sum()\n",
    "    \n",
    "    return pd.Series({'words_unique': wordlist, 'words_count_unique': countlist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:44:36.098526Z",
     "start_time": "2019-03-01T16:44:36.085366Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['wmd_ft', 'wmd_wv']\n",
    "# methods = ['ju','js','jc','ft']\n",
    "fields = ['title', 'spot', 'text']\n",
    "methods_cross = [met + '_' + field for met in methods for field in fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:46:47.361783Z",
     "start_time": "2019-03-01T16:46:45.663921Z"
    }
   },
   "outputs": [],
   "source": [
    "for field in fields:\n",
    "    df_tmp = df_news[field + '_pp_str'].apply(get_freq_unique)\n",
    "    df_news['words_unique_' + field] = df_tmp['words_unique']\n",
    "    df_news['words_count_unique_' + field] = df_tmp['words_count_unique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T14:44:22.030049Z",
     "start_time": "2019-03-01T14:44:16.512525Z"
    }
   },
   "outputs": [],
   "source": [
    "ftmodel = fastText.load_model('../../data/model/downloads/haber-P1_S1_L1-100E.bin')\n",
    "model_w2v = Word2Vec.load('../../data/model/downloads/reaction.all.1544173485.punct_True.stopwords_True.lemmatized_True.w2v_100V_5E_1547415130.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T16:31:28.829590Z",
     "start_time": "2019-03-01T16:31:28.824761Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:19:32.869453Z",
     "start_time": "2019-03-01T17:19:32.852531Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_w2v(wordlist):\n",
    "    \n",
    "    tmp = [(index, word) for index, word in enumerate(wordlist) if word in model_w2v.wv.vocab]\n",
    "    \n",
    "    if len(tmp) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    indexes_in, words_in = list(zip(*tmp))\n",
    "    \n",
    "    count = len(words_in)\n",
    "    \n",
    "    X = np.zeros((count, model_w2v.wv.vector_size))\n",
    "    \n",
    "    for i, word in enumerate(words_in):\n",
    "        X[i,:] = model_w2v.wv.word_vec(word)\n",
    "    \n",
    "    return X, np.array(indexes_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:09:37.698954Z",
     "start_time": "2019-03-01T17:09:37.693355Z"
    }
   },
   "outputs": [],
   "source": [
    "words1 = row1['words_unique_'+field]\n",
    "words2 = row2['words_unique_'+field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:14:01.386017Z",
     "start_time": "2019-03-01T17:14:01.375432Z"
    }
   },
   "outputs": [],
   "source": [
    "X1 = np.concatenate([ftmodel.get_word_vector(word).reshape(1,-1) for word in words1], axis=0)\n",
    "X2 = np.concatenate([ftmodel.get_word_vector(word).reshape(1,-1) for word in words2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:14:04.081026Z",
     "start_time": "2019-03-01T17:14:04.071224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 100)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:24:45.306242Z",
     "start_time": "2019-03-01T17:20:17.305541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "title\t\n",
      "0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000,\n",
      "\n",
      "spot\t\n",
      "0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000,\n",
      "\n",
      "text\t\n",
      "0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000,16000,"
     ]
    }
   ],
   "source": [
    "for field in fields:\n",
    "    \n",
    "    print('\\n\\n'+field+'\\t')\n",
    "    \n",
    "    for index, row in df_comparisons.iterrows():\n",
    "        \n",
    "        if index % 1000 == 0:\n",
    "            print(index, end=',')\n",
    "#         print(index)\n",
    "        # JU, JS and JC scores\n",
    "        row1 = df_news.iloc[int(row.ind0)]\n",
    "        row2 = df_news.iloc[int(row.ind1)]\n",
    "        \n",
    "        words1 = row1['words_unique_'+field]\n",
    "        words2 = row2['words_unique_'+field]\n",
    "        \n",
    "        if len(words1) == 0 or len(words2) == 0:\n",
    "            df_comparisons.loc[index, 'wmd_wv_'+field] = None\n",
    "            df_comparisons.loc[index, 'wmd_ft_'+field] = None\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        # Fasttext\n",
    "            \n",
    "        X1 = np.concatenate([ftmodel.get_word_vector(word).reshape(1,-1) for word in words1], axis=0)\n",
    "        X2 = np.concatenate([ftmodel.get_word_vector(word).reshape(1,-1) for word in words2], axis=0)\n",
    "        \n",
    "        d1 = row1['words_count_unique_'+field]\n",
    "        d2 = row2['words_count_unique_'+field]\n",
    "        \n",
    "        d1 = d1 / d1.sum()\n",
    "        d2 = d2 / d2.sum()\n",
    "\n",
    "        C = np.sqrt(((np.expand_dims(X1, 1) - np.expand_dims(X2, 0)) ** 2).sum(axis=-1))\n",
    "\n",
    "        T1 = np.zeros_like(C)\n",
    "        T1[np.arange(T1.shape[0]), C.argmin(axis=1)] = d1\n",
    "        T2 = np.zeros_like(C)\n",
    "        T2[C.argmin(axis=0), np.arange(T2.shape[1])] = d2\n",
    "\n",
    "        dist = max(np.sum(T1 * C), np.sum(T2 * C))\n",
    "        \n",
    "        df_comparisons.loc[index, 'wmd_ft_'+field] = dist\n",
    "        \n",
    "        \n",
    "        # Word2Vec\n",
    "        \n",
    "        X1, indexes1 = get_w2v(words1)\n",
    "        X2, indexes2 = get_w2v(words2)\n",
    "        \n",
    "        if X1 is None or X2 is None:\n",
    "            df_comparisons.loc[index, 'wmd_wv_'+field] = None\n",
    "            continue\n",
    "        \n",
    "        d1 = row1['words_count_unique_'+field][indexes1]\n",
    "        d2 = row2['words_count_unique_'+field][indexes2]\n",
    "        \n",
    "        d1 = d1 / d1.sum()\n",
    "        d2 = d2 / d2.sum()\n",
    "\n",
    "        C = np.sqrt(((np.expand_dims(X1, 1) - np.expand_dims(X2, 0)) ** 2).sum(axis=-1))\n",
    "\n",
    "        T1 = np.zeros_like(C)\n",
    "        T1[np.arange(T1.shape[0]), C.argmin(axis=1)] = d1\n",
    "        T2 = np.zeros_like(C)\n",
    "        T2[C.argmin(axis=0), np.arange(T2.shape[1])] = d2\n",
    "\n",
    "        dist = max(np.sum(T1 * C), np.sum(T2 * C))\n",
    "        \n",
    "        df_comparisons.loc[index, 'wmd_wv_'+field] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:23.851487Z",
     "start_time": "2019-03-01T17:25:23.846668Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comparisons_bu = df_comparisons.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:24.327532Z",
     "start_time": "2019-03-01T17:25:24.318552Z"
    }
   },
   "outputs": [],
   "source": [
    "for met in methods:\n",
    "    for field in fields:\n",
    "        df_comparisons[met+'_'+field] = df_comparisons[met+'_'+field].max() - df_comparisons[met+'_'+field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:25.597594Z",
     "start_time": "2019-03-01T17:25:25.546258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmd_ft_title 913 3.26193613620173\n",
      "wmd_ft_spot 241 2.957422562977026\n",
      "wmd_ft_text 0 2.612090747701467\n",
      "wmd_wv_title 913 3.3672491963278097\n",
      "wmd_wv_spot 241 3.109255528833871\n",
      "wmd_wv_text 0 2.709321780494125\n"
     ]
    }
   ],
   "source": [
    "for met in methods:\n",
    "    for field in fields:\n",
    "        colnow = met+'_'+field\n",
    "        missings_now = df_comparisons_bu[colnow].isnull()\n",
    "        meannow = df_comparisons_bu[~missings_now][colnow].mean()\n",
    "        df_comparisons.loc[missings_now, colnow] = meannow\n",
    "        print(colnow, missings_now.sum(), meannow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:27.502948Z",
     "start_time": "2019-03-01T17:25:27.464131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmd_ft_title 0 2.714834635639943\n",
      "wmd_ft_spot 0 3.1387388889676076\n",
      "wmd_ft_text 0 3.0158003159887183\n",
      "wmd_wv_title 0 2.677124345675647\n",
      "wmd_wv_spot 0 1.7750465242013165\n",
      "wmd_wv_text 0 1.9120923118631081\n"
     ]
    }
   ],
   "source": [
    "for met in methods:\n",
    "    for field in fields:\n",
    "        colnow = met+'_'+field\n",
    "        missings_now = df_comparisons[colnow].isnull()\n",
    "        meannow = df_comparisons[~missings_now][colnow].mean()\n",
    "        print(colnow, missings_now.sum(), meannow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:25:30.149289Z",
     "start_time": "2019-03-01T17:25:30.137273Z"
    }
   },
   "outputs": [],
   "source": [
    "def prec_recall(tp, fp, fn):\n",
    "\n",
    "    return float(tp / (tp + fp)), float(tp / (tp + fn))\n",
    "\n",
    "def find_eacc(labels_now, preds_now):\n",
    "    labels_now = labels_now.flatten()\n",
    "    preds_now = preds_now.flatten()\n",
    "    \n",
    "    precs, recalls, thresholds = precision_recall_curve(labels_now, preds_now)\n",
    "    \n",
    "    indnow = np.argmin(np.abs(precs-recalls))\n",
    "    eacc = (precs[indnow] + recalls[indnow]) / 2\n",
    "    thr = thresholds[indnow]\n",
    "    \n",
    "    true_positive = np.logical_and(preds_now>=thr, labels_now==1).sum()\n",
    "    true_negative = np.logical_and(preds_now<thr, labels_now==0).sum()\n",
    "    false_positive = np.logical_and(preds_now>=thr, labels_now==0).sum()\n",
    "    false_negative = np.logical_and(preds_now<thr, labels_now==1).sum()\n",
    "    \n",
    "    precision, recall = prec_recall(true_positive, false_positive, false_negative)\n",
    "    \n",
    "    f1 = 2*(recall * precision) / (recall + precision)\n",
    "    \n",
    "    out = dict(thr=thr,eacc=eacc, precision=precision, recall=recall, f1=f1,\n",
    "              tp=true_positive, tn=true_negative,\n",
    "               fp=false_positive, fn=false_negative,\n",
    "               precs=precs, recalls=recalls\n",
    "               )\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:27.996695Z",
     "start_time": "2019-03-01T17:26:27.967961Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for met in methods:\n",
    "    for field in fields:\n",
    "        method = met + '_' + field\n",
    "        results[method] = find_eacc(df_comparisons.label.values, df_comparisons[method].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.122562Z",
     "start_time": "2019-03-01T17:26:28.116135Z"
    }
   },
   "outputs": [],
   "source": [
    "def tabulate_res(resnow):\n",
    "\n",
    "    table = []\n",
    "    for key, val in resnow.items():\n",
    "        table.append(\n",
    "            [key, resnow[key]['eacc'], resnow[key]['f1'], resnow[key]['precision'], resnow[key]['recall'], resnow[key]['thr'], resnow[key]['tp'], resnow[key]['tn'], resnow[key]['fp'],\n",
    "             resnow[key]['fn']])\n",
    "\n",
    "    return tabulate(table, headers=['', 'E-ACC', 'F1', 'PREC', 'RECALL', 'THR', 'TP', 'TN', 'FP', 'FN'], tablefmt=\"fancy_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.259980Z",
     "start_time": "2019-03-01T17:26:28.255317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤══════════╤══════════╤══════════╤══════════╤═════════╤══════╤═══════╤══════╤══════╕\n",
      "│              │    E-ACC │       F1 │     PREC │   RECALL │     THR │   TP │    TN │   FP │   FN │\n",
      "╞══════════════╪══════════╪══════════╪══════════╪══════════╪═════════╪══════╪═══════╪══════╪══════╡\n",
      "│ wmd_ft_title │ 0.829925 │ 0.829925 │ 0.829925 │ 0.829925 │ 3.31806 │ 1542 │ 14684 │  316 │  316 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_ft_spot  │ 0.938644 │ 0.938644 │ 0.938644 │ 0.938644 │ 3.59613 │ 1744 │ 14886 │  114 │  114 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_ft_text  │ 0.926265 │ 0.926265 │ 0.926265 │ 0.926265 │ 3.50614 │ 1721 │ 14863 │  137 │  137 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_title │ 0.8485   │ 0.846501 │ 0.88968  │ 0.80732  │ 3.36949 │ 1500 │ 14814 │  186 │  358 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_spot  │ 0.876211 │ 0.876211 │ 0.876211 │ 0.876211 │ 2.6212  │ 1628 │ 14770 │  230 │  230 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_text  │ 0.944026 │ 0.944026 │ 0.944026 │ 0.944026 │ 2.4242  │ 1754 │ 14896 │  104 │  104 │\n",
      "╘══════════════╧══════════╧══════════╧══════════╧══════════╧═════════╧══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_res(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.389694Z",
     "start_time": "2019-03-01T17:26:28.386450Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_score(dfnow, colname, thrnow):\n",
    "    \n",
    "    stdnow = dfnow[colname].std()\n",
    "    \n",
    "    print(\"%s\\t==>\\tstd: %.4f, old_thr: %.4f\" % (colname, stdnow, thrnow))\n",
    "    \n",
    "    return (dfnow[colname] - thrnow ) / stdnow, stdnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.537198Z",
     "start_time": "2019-03-01T17:26:28.528065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wmd_ft_title',\n",
       " 'wmd_ft_spot',\n",
       " 'wmd_ft_text',\n",
       " 'wmd_wv_title',\n",
       " 'wmd_wv_spot',\n",
       " 'wmd_wv_text']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.637361Z",
     "start_time": "2019-03-01T17:26:28.625892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wmd_ft_title\t==>\tstd: 0.7643, old_thr: 3.3181\n",
      "wmd_ft_spot\t==>\tstd: 0.7576, old_thr: 3.5961\n",
      "wmd_ft_text\t==>\tstd: 0.7648, old_thr: 3.5061\n",
      "wmd_wv_title\t==>\tstd: 0.7608, old_thr: 3.3695\n",
      "wmd_wv_spot\t==>\tstd: 0.7788, old_thr: 2.6212\n",
      "wmd_wv_text\t==>\tstd: 0.7364, old_thr: 2.4242\n"
     ]
    }
   ],
   "source": [
    "for method in methods_cross:\n",
    "    dsnow, stdnow = normalize_score(df_comparisons, method, results[method]['thr'])\n",
    "    df_comparisons[method+'_norm'] = dsnow\n",
    "    results[method]['std_norm'] = stdnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.788034Z",
     "start_time": "2019-03-01T17:26:28.783960Z"
    }
   },
   "outputs": [],
   "source": [
    "methods_cross_norm = [met+'_norm' for met in methods_cross]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:28.890632Z",
     "start_time": "2019-03-01T17:26:28.887223Z"
    }
   },
   "outputs": [],
   "source": [
    "field_weights = {'spot': 0.3, 'title': 0.1, 'text': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:29.003741Z",
     "start_time": "2019-03-01T17:26:28.999834Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_av(rownow, weights_field, metsnow):\n",
    "    \n",
    "    score = 0\n",
    "    count = 0\n",
    "    \n",
    "    for method in metsnow:\n",
    "        count += 1\n",
    "        for field in fields:\n",
    "            score += weights_field[field] * rownow[method + '_' + field + '_norm']\n",
    "            \n",
    "    return score / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:30.480312Z",
     "start_time": "2019-03-01T17:26:29.505663Z"
    }
   },
   "outputs": [],
   "source": [
    "for met in methods:\n",
    "    df_comparisons[met + '_all'] = df_comparisons.apply(lambda row: weighted_av(row, field_weights, [met]), axis=1)\n",
    "    results.update({met + '_all': find_eacc(df_comparisons.label.values, df_comparisons[met + '_all'].values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:30.491502Z",
     "start_time": "2019-03-01T17:26:30.482281Z"
    }
   },
   "outputs": [],
   "source": [
    "results.update({met+'_all': find_eacc(df_comparisons.label.values, df_comparisons[met+'_all'].values) for met in methods})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:26:31.166407Z",
     "start_time": "2019-03-01T17:26:31.154468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════╤══════════╤══════════╤══════════╤══════════╤═════════════╤══════╤═══════╤══════╤══════╕\n",
      "│              │    E-ACC │       F1 │     PREC │   RECALL │         THR │   TP │    TN │   FP │   FN │\n",
      "╞══════════════╪══════════╪══════════╪══════════╪══════════╪═════════════╪══════╪═══════╪══════╪══════╡\n",
      "│ wmd_ft_title │ 0.829925 │ 0.829925 │ 0.829925 │ 0.829925 │  3.31806    │ 1542 │ 14684 │  316 │  316 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_ft_spot  │ 0.938644 │ 0.938644 │ 0.938644 │ 0.938644 │  3.59613    │ 1744 │ 14886 │  114 │  114 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_ft_text  │ 0.926265 │ 0.926265 │ 0.926265 │ 0.926265 │  3.50614    │ 1721 │ 14863 │  137 │  137 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_title │ 0.8485   │ 0.846501 │ 0.88968  │ 0.80732  │  3.36949    │ 1500 │ 14814 │  186 │  358 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_spot  │ 0.876211 │ 0.876211 │ 0.876211 │ 0.876211 │  2.6212     │ 1628 │ 14770 │  230 │  230 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_text  │ 0.944026 │ 0.944026 │ 0.944026 │ 0.944026 │  2.4242     │ 1754 │ 14896 │  104 │  104 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_ft_all   │ 0.964478 │ 0.964478 │ 0.964478 │ 0.964478 │ -0.00476043 │ 1792 │ 14934 │   66 │   66 │\n",
      "├──────────────┼──────────┼──────────┼──────────┼──────────┼─────────────┼──────┼───────┼──────┼──────┤\n",
      "│ wmd_wv_all   │ 0.97578  │ 0.97578  │ 0.97578  │ 0.97578  │ -0.101298   │ 1813 │ 14955 │   45 │   45 │\n",
      "╘══════════════╧══════════╧══════════╧══════════╧══════════╧═════════════╧══════╧═══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_res(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:27:17.266896Z",
     "start_time": "2019-03-01T17:27:16.003747Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comparisons.to_csv('df_comparisons_unsup_lemma_wmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:27:36.186107Z",
     "start_time": "2019-03-01T17:27:36.170583Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('unsupervised_results_lemma_wmd.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
